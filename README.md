# Multimodal Sentiment Analysis in Conversational Videos Based on Recurrent Neural Networks
## Overview
The theme of this project is Multimodal Sentiment Analysis, the task is sentiment classification of conversational videos, including two sub-tasks: sentiment analysis task and emotion recognition task. Both sub-tasks aim to predict the sentiment label and emotion label of every utterance in a conversation utilizing different modalities(including textual features, audio features and visual features). 
This project is made up of 4 major parts: the first part is the key technology related to this project, the second part is the design, training and evaluation of baseline models, the third part is the design, training and evaluation of Multimodal Conversational Models, and the final section is the comparison and analysis of model performances.
## Related Dataset
The project uses Multimodal EmotionLines Dataset(MELD), which is a multimodal dataset extended from the EmotionLines dataset. MELD includes not only textual dialogues, but also their corresponding visual and audio counterparts.
